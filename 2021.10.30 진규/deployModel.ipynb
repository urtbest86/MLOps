{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\r\n",
        "import numpy as np\r\n",
        "import os"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1635577895179
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml\r\n",
        "from azureml.core import Workspace\r\n",
        "\r\n",
        "# check core SDK version number\r\n",
        "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Azure ML SDK Version:  1.34.0\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635577897155
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workspace 연결"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\r\n",
        "print('Workspace name: ' + ws.name, \r\n",
        "      'Azure region: ' + ws.location, \r\n",
        "      'Subscription id: ' + ws.subscription_id, \r\n",
        "      'Resource group: ' + ws.resource_group, sep='\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace name: mlrgeast\nAzure region: eastus\nSubscription id: 932c3e14-d0cf-4e41-9998-bdebb9bfa1cf\nResource group: mlrg\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635577901181
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실험 연결"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "experiment_name = 'myExp'\r\n",
        "\r\n",
        "exp = Experiment(workspace=ws, name=experiment_name)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635577902993
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 생성할 모델 코드 확인"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_folder = './'\r\n",
        "os.makedirs(script_folder, exist_ok=True)\r\n",
        "\r\n",
        "with open(os.path.join(script_folder, 'myModel.py'), 'r') as f:\r\n",
        "    print(f.read())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "import pandas as pd\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n\n\nDATA_PATH=\"https://raw.githubusercontent.com/urtbest86/MLOps/master/result_train_dataset2.csv\"\ndf = pd.read_csv(DATA_PATH)\n\nDATA_PATH=\"https://raw.githubusercontent.com/urtbest86/MLOps/master/result_test_dataset2.csv\"\ntest = pd.read_csv(DATA_PATH)\n\ntrain=df.sample(frac=0.8)\nval=df.sample(frac=0.2)\n\nmean = train.mean(axis=0)\ntrain -= mean\nstd = train.std(axis=0)\ntrain /= std\n\ntest -= mean\ntest /= std\n\nval-=mean\nval/=std\n\ntrain_data_set = train.values\nx_train = train_data_set[:, 2:-1].astype(float)\ny_train = train_data_set[:, -1].astype(float)\n\ntest_data_set = test.values\nx_test = test_data_set[:, 2:-1].astype(float)\ny_test = test_data_set[:, -1].astype(float)\n\nval_data_set = val.values\nx_val = val_data_set[:, 2:-1].astype(float)\ny_val = val_data_set[:, -1].astype(float)\n\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nmodel = Sequential()\nmodel.add(Dense(1024, input_dim = 4, activation='relu'))\nmodel.add(Dense(500,activation='relu'))\nmodel.add(Dense(300,activation='relu'))\nmodel.add(Dense(200,activation='relu'))\nmodel.add(Dense(1))\n\n\nrgs=model.compile(loss='mse', optimizer='adam',metrics=['mae'])\n\neph_size=1\nhist=model.fit(x_train, y_train, epochs=eph_size, batch_size=4,validation_data=(x_val,y_val))\n\n\nlaoss_nd_metrics = model.evaluate(x_test, y_test, batch_size=32)\n\n\n\nfrom azureml.core.run import Run\n# start an Azure ML run\nrun = Run.get_context()\n\n# log a single value\nrun.log(\"Final test loss(mse)\", laoss_nd_metrics[0])\nprint('Test loss(mse):', laoss_nd_metrics[0])\n\nrun.log('Final test loss(mae)', laoss_nd_metrics[1])\nprint('Test loss(mae):', laoss_nd_metrics[1])\n\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(6, 3))\nplt.title('Mosquito with Keras MLP ({} epochs)'.format(eph_size), fontsize=14)\nplt.plot(hist.history['loss'], 'b-', label='loss', lw=4, alpha=0.5)\nplt.plot(hist.history['val_loss'], 'r--', label='val_loss', lw=4, alpha=0.5)\nplt.legend(fontsize=12)\nplt.grid(True)\nplt.show()\nrun.log_image('loss VS val_loss', plot=plt)\n\n\nimport joblib\nimport os\n\nos.makedirs('outputs', exist_ok=True)\n# note file saved in the outputs folder is automatically uploaded into experiment record\njoblib.dump(value=hist, filename='outputs/Youjin_test_model.pkl')\n\n\n\n'''import matplotlib.pyplot as plt\n\nplt.plot(model.predict(x_test),label='predict value')\nplt.plot(y_test, label='real value')\nplt.plot(model.predict(x_test))\nplt.legend()\nplt.show()\n\n\nfrom azureml.core import Run\n\nrun = Run.get_context()\n\nscore = model.evaluate(x_test, y_test, verbose=0)\n\nrun.log_image('Accuracy vs Loss', plot=plt)'''\n\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635577904805
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 기존 compute resource에 연결"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''from azureml.core.compute import AmlCompute\r\n",
        "from azureml.core.compute import ComputeTarget\r\n",
        "import os\r\n",
        "\r\n",
        "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"test-cluster\")\r\n",
        "\r\n",
        "if compute_name in ws.compute_targets:\r\n",
        "    compute_target = ws.compute_targets[compute_name]\r\n",
        "    if compute_target and type(compute_target) is AmlCompute:\r\n",
        "        print(\"found compute target: \" + compute_name)\r\n",
        "else:\r\n",
        "    print(\"creating new compute target...\")'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "'from azureml.core.compute import AmlCompute\\nfrom azureml.core.compute import ComputeTarget\\nimport os\\n\\ncompute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"test-cluster\")\\n\\nif compute_name in ws.compute_targets:\\n    compute_target = ws.compute_targets[compute_name]\\n    if compute_target and type(compute_target) is AmlCompute:\\n        print(\"found compute target: \" + compute_name)\\nelse:\\n    print(\"creating new compute target...\")'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635577570878
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# compute resource 존재 확인 후 생성 또는 연결"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\r\n",
        "from azureml.core.compute import ComputeTarget\r\n",
        "import os\r\n",
        "\r\n",
        "# choose a name for your cluster\r\n",
        "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\r\n",
        "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\r\n",
        "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\r\n",
        "\r\n",
        "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\r\n",
        "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D11_V2\")\r\n",
        "\r\n",
        "\r\n",
        "if compute_name in ws.compute_targets:\r\n",
        "    compute_target = ws.compute_targets[compute_name]\r\n",
        "    if compute_target and type(compute_target) is AmlCompute:\r\n",
        "        print(\"found compute target: \" + compute_name)\r\n",
        "else:\r\n",
        "    print(\"creating new compute target...\")\r\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\r\n",
        "                                                                min_nodes = compute_min_nodes, \r\n",
        "                                                                max_nodes = compute_max_nodes)\r\n",
        "\r\n",
        "    # create the cluster\r\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\r\n",
        "    \r\n",
        "    # can poll for a minimum number of nodes and for a specific timeout. \r\n",
        "    # if no min node count is provided it will use the scale settings for the cluster\r\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\r\n",
        "    \r\n",
        "     # For a more detailed view of current AmlCompute status, use get_status()\r\n",
        "    print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "found compute target: cpu-cluster\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635577908512
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workspace에 환경 등록"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_dependencies.yml\r\n",
        "\r\n",
        "channels:\r\n",
        "- conda-forge\r\n",
        "dependencies:\r\n",
        "- python=3.6.2\r\n",
        "\r\n",
        "- pip:\r\n",
        "  - h5py<=2.10.0\r\n",
        "  - azureml-defaults\r\n",
        "  - tensorflow-gpu==2.0.0\r\n",
        "  - keras<=2.3.1\r\n",
        "  - matplotlib\r\n",
        "  - pandas\r\n",
        "  - scikit-learn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting conda_dependencies.yml\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실험에 코드 실행 환경 등록"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\r\n",
        "\r\n",
        "env = Environment.from_conda_specification(name = 'keras-2.3.1', file_path = './conda_dependencies.yml')\r\n",
        "\r\n",
        "'''# Specify a GPU base image\r\n",
        "env.docker.enabled = True\r\n",
        "env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.0-cudnn7-ubuntu18.04'''\r\n",
        "\r\n",
        "env.register(workspace = ws)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "{\n    \"databricks\": {\n        \"eggLibraries\": [],\n        \"jarLibraries\": [],\n        \"mavenLibraries\": [],\n        \"pypiLibraries\": [],\n        \"rcranLibraries\": []\n    },\n    \"docker\": {\n        \"arguments\": [],\n        \"baseDockerfile\": null,\n        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1\",\n        \"baseImageRegistry\": {\n            \"address\": null,\n            \"password\": null,\n            \"registryIdentity\": null,\n            \"username\": null\n        },\n        \"enabled\": false,\n        \"platform\": {\n            \"architecture\": \"amd64\",\n            \"os\": \"Linux\"\n        },\n        \"sharedVolumes\": true,\n        \"shmSize\": null\n    },\n    \"environmentVariables\": {\n        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n    },\n    \"inferencingStackVersion\": null,\n    \"name\": \"keras-2.3.1\",\n    \"python\": {\n        \"baseCondaEnvironment\": null,\n        \"condaDependencies\": {\n            \"channels\": [\n                \"conda-forge\"\n            ],\n            \"dependencies\": [\n                \"python=3.6.2\",\n                {\n                    \"pip\": [\n                        \"h5py<=2.10.0\",\n                        \"azureml-defaults\",\n                        \"tensorflow-gpu==2.0.0\",\n                        \"keras<=2.3.1\",\n                        \"matplotlib\",\n                        \"pandas\",\n                        \"scikit-learn\"\n                    ]\n                }\n            ],\n            \"name\": \"azureml_a8a0845f249cc373e9e7168f4f641be5\"\n        },\n        \"condaDependenciesFile\": null,\n        \"interpreterPath\": \"python\",\n        \"userManagedDependencies\": false\n    },\n    \"r\": null,\n    \"spark\": {\n        \"packages\": [],\n        \"precachePackages\": true,\n        \"repositories\": []\n    },\n    \"version\": \"1\"\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635577915056
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 실행 구성 및 제출\r\n",
        "### ScriptRunConfig 만들기\r\n",
        "\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델에 대한 정보들 적어주기"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import ScriptRunConfig\r\n",
        "\r\n",
        "args = ['--data-folder', \r\n",
        "        '--batch-size', 4,\r\n",
        "        '--first-layer-neurons', 1024,\r\n",
        "        '--second-layer-neurons', 500,\r\n",
        "        '--third-layer-neurons', 300,\r\n",
        "        '--forth-layer-neurons', 200,\r\n",
        "        '--learning-rate', 0.001]\r\n",
        "\r\n",
        "src = ScriptRunConfig(source_directory=script_folder,\r\n",
        "                      script='myModel.py',\r\n",
        "                      arguments=args,\r\n",
        "                      compute_target=compute_name,\r\n",
        "                      environment=env)"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635577916341
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = exp.submit(src)"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635578184575
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\r\n",
        "RunDetails(run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb9f4d34f1c0460395e54d7e9a10fcbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/myExp_1635578180_f782f42a?wsid=/subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourcegroups/mlrg/workspaces/mlrgeast&tid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65\", \"run_id\": \"myExp_1635578180_f782f42a\", \"run_properties\": {\"run_id\": \"myExp_1635578180_f782f42a\", \"created_utc\": \"2021-10-30T07:16:23.64913Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"5671372d-58d1-43c8-b425-5ed854c15325\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":2}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-10-30T07:17:11.173537Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\": \"https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/azureml-logs/55_azureml-execution-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt?sv=2019-07-07&sr=b&sig=dsdwG3A1fueHg7ZPgC%2FPyaM3W9JEoN33lieY30JKu%2Fg%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T08%3A04%3A58Z&se=2021-10-30T16%3A14%3A58Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\": \"https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/azureml-logs/65_job_prep-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt?sv=2019-07-07&sr=b&sig=pNUtHu3vaOYIw1B4H12vfeVkA6Sr%2FHSa7hqA6cnUvWg%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T08%3A04%3A58Z&se=2021-10-30T16%3A14%3A58Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=T3AqL4rF54xvgrn275oCbeslUTlSBlj%2BiByNJBFO%2BFg%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T08%3A04%3A58Z&se=2021-10-30T16%3A14%3A58Z&sp=r\", \"azureml-logs/75_job_post-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\": \"https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/azureml-logs/75_job_post-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt?sv=2019-07-07&sr=b&sig=V%2FDKqNF3bEACsQobzB8SOYyDEw3EeSA0ywPWnh%2F3YsM%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T08%3A04%3A58Z&se=2021-10-30T16%3A14%3A58Z&sp=r\", \"azureml-logs/process_info.json\": \"https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=HlaKzQ5jiAgTcFzdTvUsRqqctL46Sk0glPzGV2N3FZs%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T08%3A04%3A58Z&se=2021-10-30T16%3A14%3A58Z&sp=r\", \"azureml-logs/process_status.json\": \"https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=3b3HcN5D47Q17Q9nvyt7sQxyr0ytCeDFk2Vo%2BzDe0d0%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T08%3A04%3A58Z&se=2021-10-30T16%3A14%3A58Z&sp=r\", \"logs/azureml/94_azureml.log\": \"https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/logs/azureml/94_azureml.log?sv=2019-07-07&sr=b&sig=N7huLGa32iPXF0BFfHXLRSdQ9Z8iYCeDPF7VCPR9BAA%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T08%3A04%3A58Z&se=2021-10-30T16%3A14%3A58Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=2spDO5O%2F26htMaWgdgbUVdiwXWqaFPb8Kr6HBjagnME%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T08%3A04%3A58Z&se=2021-10-30T16%3A14%3A58Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=nR35hXAJ%2F3t%2F%2FaSa5D6lAL8T5eZW1v16TYPCovEv5kA%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T08%3A04%3A58Z&se=2021-10-30T16%3A14%3A58Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\"], [\"logs/azureml/94_azureml.log\"]], \"run_duration\": \"0:00:47\", \"run_number\": \"5\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Final test loss(mse)\", \"run_id\": \"myExp_1635578180_f782f42a\", \"categories\": [0], \"series\": [{\"data\": [0.36707951805808325]}]}, {\"name\": \"Final test loss(mae)\", \"run_id\": \"myExp_1635578180_f782f42a\", \"categories\": [0], \"series\": [{\"data\": [0.5233289003372192]}]}, {\"name\": \"loss VS val_loss\", \"run_id\": \"myExp_1635578180_f782f42a\", \"categories\": [0], \"series\": [{\"data\": [\"aml://artifactId/ExperimentRun/dcid.myExp_1635578180_f782f42a/loss VS val_loss_1635578208.png\"]}]}], \"run_logs\": \"2021-10-30 07:16:41,972|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-10-30 07:16:41,979|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-10-30 07:16:41,979|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-10-30 07:16:41,979|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-10-30 07:16:42,485|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f3330cd9ea0> for run source azureml.scriptrun\\n2021-10-30 07:16:42,486|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-10-30 07:16:42,486|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-10-30 07:16:42,488|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-10-30 07:16:42,497|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-10-30 07:16:42,498|azureml.core.authentication|DEBUG|Time to expire 1814380.501937 seconds\\n2021-10-30 07:16:42,498|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-10-30 07:16:42,498|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-10-30 07:16:42,531|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:42,531|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:42,531|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:42,532|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:42,532|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:42,532|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:42,532|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:42,688|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-10-30 07:16:42,688|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-10-30 07:16:42,759|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-10-30 07:16:42,760|azureml._SubmittedRun#myExp_1635578180_f782f42a|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '5671372d-58d1-43c8-b425-5ed854c15325', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-10-30 07:16:42,760|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-10-30 07:16:42,761|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-10-30 07:16:42,761|azureml.WorkerPool|DEBUG|[START]\\n2021-10-30 07:16:42,761|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-10-30 07:16:42,761|azureml.RunStatusContext|DEBUG|[START]\\n2021-10-30 07:16:42,761|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-10-30 07:16:42,761|azureml.MetricsClient|DEBUG|[START]\\n2021-10-30 07:16:42,761|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-10-30 07:16:42,761|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-10-30 07:16:42,761|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-10-30 07:16:42,761|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a\\n2021-10-30 07:16:42,762|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-10-30 07:16:42,762|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a\\n2021-10-30 07:16:47,142|azureml.core.run|DEBUG|Identity in use is not set. Falling back to using AMLToken\\n2021-10-30 07:16:47,142|azureml.core.run|DEBUG|Using AMLToken auth for remote run\\n2021-10-30 07:16:47,143|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-10-30 07:16:47,143|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:47,143|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:47,143|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:47,144|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:47,144|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:47,144|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:47,144|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.api.azureml.ms.\\n2021-10-30 07:16:47,183|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-10-30 07:16:47,183|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-10-30 07:16:47,243|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-10-30 07:16:47,245|azureml._SubmittedRun#myExp_1635578180_f782f42a|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '5671372d-58d1-43c8-b425-5ed854c15325', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-10-30 07:16:47,245|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-10-30 07:16:47,246|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-10-30 07:16:47,246|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-10-30 07:16:47,246|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-10-30 07:16:48,232|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.ArtifactsClient|DEBUG|Called upload_artifact\\n2021-10-30 07:16:48,232|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.ArtifactsClient|DEBUG|Uploading io artifact\\n2021-10-30 07:16:48,232|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2021-10-30 07:16:48,232|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2021-10-30 07:16:48,247|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-10-30 07:16:48,247|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-10-30 07:16:48,247|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 2.\\n2021-10-30 07:16:48,248|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-10-30 07:16:48,248|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-10-30 07:16:48,248|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-10-30 07:16:48,248|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-10-30 07:16:48,248|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-10-30 07:16:48,249|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-10-30 07:16:48,248|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-10-30 07:16:48,250|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 2 values.\\n2021-10-30 07:16:48,251|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-10-30 07:16:48,251|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2021-10-30 07:16:48,251|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-10-30 07:16:48,251|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-10-30 07:16:48,411|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2021-10-30 07:16:48,412|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2021-10-30 07:16:48,450|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-10-30 07:16:48,499|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-10-30 07:16:48,499|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-10-30 07:16:48,499|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-10-30 07:16:48,499|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Waiting on task: 0__handle_batch.\\n1 tasks left. Current duration of flush 0.00018525123596191406 seconds.\\n\\n2021-10-30 07:16:48,499|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-10-30 07:16:48,574|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.myExp_1635578180_f782f42a/loss VS val_loss_1635578208.png with size 16559, file size 16559.\\n2021-10-30 07:16:48,625|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-10-30 07:16:48,632|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a\\n2021-10-30 07:16:48,632|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a to /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a\\n2021-10-30 07:16:48,632|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a\\n2021-10-30 07:16:48,632|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-10-30 07:16:48,632|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-10-30 07:16:48,632|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-10-30 07:16:48,632|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-10-30 07:16:48,632|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-10-30 07:16:48,633|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-10-30 07:16:48,633|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-10-30 07:16:48,633|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-10-30 07:16:48,633|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-10-30 07:16:48,633|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-10-30 07:16:48,633|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:48,633|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-10-30 07:16:48,634|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-10-30 07:16:48,634|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-10-30 07:16:48,634|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-10-30 07:16:48,634|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-10-30 07:16:48,634|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-10-30 07:16:48,634|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-10-30 07:16:48,634|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:48,634|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:48,634|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-10-30 07:16:48,634|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-10-30 07:16:48,688|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-10-30 07:16:49,248|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2021-10-30 07:16:49,248|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2021-10-30 07:16:49,248|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 1.\\n2021-10-30 07:16:49,248|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2021-10-30 07:16:49,248|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2021-10-30 07:16:49,249|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 1 values.\\n2021-10-30 07:16:49,249|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2021-10-30 07:16:49,249|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2021-10-30 07:16:49,249|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[START]\\n2021-10-30 07:16:49,249|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2021-10-30 07:16:49,249|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 1__log_batch_v2 to queue of approximate size: 1\\n2021-10-30 07:16:49,250|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling _post_run_metrics_log_failed_validations with url None\\n2021-10-30 07:16:49,250|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2021-10-30 07:16:49,258|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2021-10-30 07:16:49,258|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2021-10-30 07:16:49,258|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2021-10-30 07:16:49,258|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2021-10-30 07:16:49,258|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2021-10-30 07:16:49,259|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2021-10-30 07:16:49,259|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2021-10-30 07:16:49,398|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient._post_run_metrics_log_failed_validations-async:False|DEBUG|[STOP]\\n2021-10-30 07:16:53,693|azureml._restclient.clientbase|DEBUG|ClientBase: Calling update_status with url None\\n2021-10-30 07:16:53,752|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:53,752|azureml.MetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:53,752|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-10-30 07:16:53,752|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-10-30 07:16:53,752|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-10-30 07:16:53,752|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-10-30 07:16:53,752|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-10-30 07:16:53,752|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:53,753|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-10-30 07:16:53,753|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 300 is different from task queue timeout 120, using flush timeout\\n2021-10-30 07:16:53,753|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 300 seconds on tasks: [].\\n2021-10-30 07:16:53,753|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-10-30 07:16:53,753|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:53,753|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:53,753|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-10-30 07:16:53,753|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-10-30 07:16:53,813|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-10-30 07:16:53,813|azureml.RunStatusContext|DEBUG|[STOP]\\n2021-10-30 07:16:53,813|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-10-30 07:16:53,813|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-10-30 07:16:53,813|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-10-30 07:16:53,813|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-10-30 07:16:53,813|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-10-30 07:16:53,814|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:53,814|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-10-30 07:16:53,814|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-10-30 07:16:53,814|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-10-30 07:16:53,814|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-10-30 07:16:53,814|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:53,814|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:53,814|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-10-30 07:16:53,814|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-10-30 07:16:53,894|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-10-30 07:16:53,894|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-10-30 07:16:53,894|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-10-30 07:16:53,894|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-10-30 07:16:53,895|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-10-30 07:16:53,895|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-10-30 07:16:53,895|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-10-30 07:16:53,895|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-10-30 07:16:53,895|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-10-30 07:16:53,895|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:53,896|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-10-30 07:16:53,896|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-10-30 07:16:53,896|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [AsyncTask(0__log_batch_v2), AsyncTask(1__log_batch_v2)].\\n2021-10-30 07:16:53,896|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-10-30 07:16:53,896|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-10-30 07:16:53,896|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-10-30 07:16:53,896|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|[START]\\n2021-10-30 07:16:53,896|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|Awaiter is PostMetricsBatchV2\\n2021-10-30 07:16:53,896|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.1__log_batch_v2.WaitingTask|DEBUG|[STOP]\\n2021-10-30 07:16:53,896|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-10-30 07:16:53,896|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:53,897|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-10-30 07:16:53,897|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-10-30 07:16:53,897|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-10-30 07:16:53,968|azureml._SubmittedRun#myExp_1635578180_f782f42a.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-10-30 07:16:53,968|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2021-10-30 07:16:53,968|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-10-30 07:16:53,968|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-10-30 07:16:53,968|azureml.WorkerPool|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.34.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635578184956
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "Run(Experiment: myExp,\nId: myExp_1635578180_f782f42a,\nType: azureml.scriptrun,\nStatus: Starting)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>myExp</td><td>myExp_1635578180_f782f42a</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/myExp_1635578180_f782f42a?wsid=/subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourcegroups/mlrg/workspaces/mlrgeast&amp;tid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635578185302
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "실행 상태를 모니터링 하고 필요에 따라 실행 로그를 스트리밍"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: myExp_1635578180_f782f42a\nWeb View: https://ml.azure.com/runs/myExp_1635578180_f782f42a?wsid=/subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourcegroups/mlrg/workspaces/mlrgeast&tid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65\n\nStreaming azureml-logs/55_azureml-execution-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\n========================================================================================================================\n\n2021-10-30T07:16:36Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=89273 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2021-10-30T07:16:36Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts/workspaceblobstore\n2021-10-30T07:16:36Z The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-30T07:16:36Z Starting output-watcher...\n2021-10-30T07:16:36Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n2021-10-30T07:16:36Z Executing 'Copy ACR Details file' on 10.0.0.4\n2021-10-30T07:16:36Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   \n>>>   \nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_dded69baa6f866c564c25bc60667a4a7\nDigest: sha256:6bd4c803ccfa9b4b42d03ccbdc1f2bd3163a964e68c7a34899c0a34d01af62db\nStatus: Image is up to date for mlcontainerregi222.azurecr.io/azureml/azureml_dded69baa6f866c564c25bc60667a4a7:latest\nmlcontainerregi222.azurecr.io/azureml/azureml_dded69baa6f866c564c25bc60667a4a7:latest\n2021-10-30T07:16:36Z The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-30T07:16:36Z Check if container myexp_1635578180_f782f42a already exist exited with 0, \n\nf563e705aa9e8056f60321ae673ff8a0b9d6018f0f6cf14ad95d9c7971808ca6\n2021-10-30T07:16:37Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n2021-10-30T07:16:37Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-31ea1d45b66e5f85d986b98a0b13d1ea-94f5cad182b9f82d-01 -sshRequired=false] \n2021/10/30 07:16:37 Got JobInfoJson from env\n2021/10/30 07:16:37 Starting App Insight Logger for task:  containerSetup\n2021/10/30 07:16:37 Version: 3.0.01755.0003 Branch: .SourceBranch Commit: 66828d8\n2021/10/30 07:16:37 Entered ContainerSetupTask - Preparing infiniband\n2021/10/30 07:16:37 Starting infiniband setup\n2021/10/30 07:16:37 Python Version found is bash: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so.5: no version information available (required by bash)\nPython 3.6.2\n\n2021/10/30 07:16:37 Returning Python Version as /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so\n2021/10/30 07:16:37 VMSize: standard_d11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n2021/10/30 07:16:37 VMSize: standard_d11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n2021-10-30T07:16:37Z VMSize: standard_d11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n2021/10/30 07:16:37 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2021/10/30 07:16:37 Not setting up Infiniband in Container\n2021/10/30 07:16:37 Not setting up Infiniband in Container\n2021-10-30T07:16:37Z Not setting up Infiniband in Container\n2021/10/30 07:16:37 Python Version found is bash: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so.5: no version information available (required by bash)\nPython 3.6.2\n\n2021/10/30 07:16:37 Returning Python Version as /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so\n2021/10/30 07:16:37 sshd inside container not required for job, skipping setup.\n2021/10/30 07:16:37 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n2021/10/30 07:16:37 App Insight Client has already been closed\n2021/10/30 07:16:37 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2021-10-30T07:16:37Z Starting docker container succeeded.\n2021-10-30T07:16:40Z The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-30T07:16:40Z The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-30T07:16:41Z Job environment preparation succeeded on 10.0.0.4. Output: \n>>>   2021/10/30 07:16:35 Got JobInfoJson from env\n>>>   2021/10/30 07:16:35 Starting App Insight Logger for task:  prepareJobEnvironment\n>>>   2021/10/30 07:16:35 Version: 3.0.01755.0003 Branch: .SourceBranch Commit: 66828d8\n>>>   2021/10/30 07:16:35 Got JobInfoJson from env\n>>>   2021/10/30 07:16:35 runtime.GOOS linux\n>>>   2021/10/30 07:16:35 Checking if '/tmp' exists\n>>>   2021/10/30 07:16:35 Reading dyanamic configs\n>>>   2021/10/30 07:16:35 Container sas url: https://baiscriptseastusprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=gCpFfTbL8hPl%2BzV43hBdfOZC4SuKqZoJraIo10S4%2FYw%3D\n>>>   2021/10/30 07:16:35 Starting Azsecpack installation on machine: 0b073b9de0144efeb89b8160802989ce000000#19411b3a-b7ca-48d9-a1e2-31694d0ccb65#932c3e14-d0cf-4e41-9998-bdebb9bfa1cf#mlrg#mlrgeast#cpu-cluster#tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d\n>>>   2021/10/30 07:16:35 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/azsecpack.variables: no such file or directory\n>>>   2021/10/30 07:16:35 Azsecpack installation directory: /mnt/batch/tasks/startup/wd/az_resource, Is Azsecpack installer on host: true. Is Azsecpack installation enabled: false,\n>>>   2021/10/30 07:16:35 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\n>>>   2021/10/30 07:16:35 Turning off azsecpack, if it is already running\n>>>   2021/10/30 07:16:35 Start deleting Azsecpack installation cronjob...\n>>>   2021/10/30 07:16:35 Start checking if Azsecpack is running...\n>>>   2021/10/30 07:16:35 Azsecpack is not running. No need to stop Azsecpack processes.\n>>>   2021/10/30 07:16:35 bypass systemd resolved\n>>>   2021/10/30 07:16:35 Cluster Subscription Id: 932c3e14-d0cf-4e41-9998-bdebb9bfa1cf\n>>>   2021/10/30 07:16:35 Cluster Workspace Name: mlrgeast\n>>>   2021/10/30 07:16:35 Cluster Name: cpu-cluster\n>>>   2021/10/30 07:16:35 VMsize: standard_d11_v2\n>>>   2021/10/30 07:16:35 GPU Count: 0\n>>>   2021/10/30 07:16:35 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n>>>   2021/10/30 07:16:35 The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/30 07:16:35 The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/30 07:16:35 Get GPU count failed with err: The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command., \n>>>   2021/10/30 07:16:35 AMLComputeXDSEndpoint:  https://eastus.cert.api.azureml.ms/xdsbatchai\n>>>   2021/10/30 07:16:35 AMLComputeXDSApiVersion:  2018-02-01\n>>>   2021/10/30 07:16:35 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/config\n>>>   2021/10/30 07:16:35 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\n>>>   2021/10/30 07:16:35 Starting identity responder.\n>>>   2021/10/30 07:16:35 Starting identity responder.\n>>>   2021/10/30 07:16:35 Logfile used for identity responder: /mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/IdentityResponderLog-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\n>>>   2021/10/30 07:16:35 Logfile used for identity responder: /mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/IdentityResponderLog-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\n>>>   2021/10/30 07:16:35 Started Identity Responder for job.\n>>>   2021/10/30 07:16:35 Started Identity Responder for job.\n>>>   2021/10/30 07:16:35 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd\n>>>   2021/10/30 07:16:35 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/shared\n>>>   2021/10/30 07:16:35 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/myExp_1635578180_f782f42a\n>>>   2021/10/30 07:16:35 From the policy service, the filtering patterns is: , data store is \n>>>   2021/10/30 07:16:35 Mounting job level file systems\n>>>   2021/10/30 07:16:35 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts\n>>>   2021/10/30 07:16:35 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/config/.amlcompute.datastorecredentials\n>>>   2021/10/30 07:16:35 Datastore credentials file not found, skipping.\n>>>   2021/10/30 07:16:35 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/config/.master.runtimesastokens\n>>>   2021/10/30 07:16:35 Runtime sas tokens file not found, skipping.\n>>>   2021/10/30 07:16:35 NFS mount is not enabled\n>>>   2021/10/30 07:16:35 No Azure File Shares configured\n>>>   2021/10/30 07:16:35 Mounting blob file systems\n>>>   2021/10/30 07:16:35 Blobfuse runtime version 1.3.6\n>>>   2021/10/30 07:16:35 Mounting azureml-blobstore-b299dd1a-720e-4f34-964c-7188f2f9435e container from strageeastus222 account at /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts/workspaceblobstore\n>>>   2021/10/30 07:16:35 Using Compute Identity to authenticate Blobfuse: false.\n>>>   2021/10/30 07:16:35 Using Compute Identity to authenticate Blobfuse: false.\n>>>   2021/10/30 07:16:36 Blobfuse cache size set to 89273 MB.\n>>>   2021/10/30 07:16:36 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=89273 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n>>>   2021/10/30 07:16:36 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts/workspaceblobstore\n>>>   2021/10/30 07:16:36 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts/workspaceblobstore\n>>>   2021/10/30 07:16:36 Successfully mounted azureml-blobstore-b299dd1a-720e-4f34-964c-7188f2f9435e container from strageeastus222 account at /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts/workspaceblobstore\n>>>   2021/10/30 07:16:36 Failed to created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts/workspaceblobstore/azureml/myExp_1635578180_f782f42a, due to mkdir /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts/workspaceblobstore/azureml/myExp_1635578180_f782f42a: read-only file system\n>>>   2021/10/30 07:16:36 No unmanaged file systems configured\n>>>   2021/10/30 07:16:36 The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/30 07:16:36 The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/30 07:16:36 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/myExp_1635578180_f782f42a\n>>>   2021/10/30 07:16:36 From the policy service, the filtering patterns is: , data store is \n>>>   2021/10/30 07:16:36 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a\n>>>   2021/10/30 07:16:36 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a\n>>>   2021/10/30 07:16:36 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a\n>>>   2021/10/30 07:16:36 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a\n>>>   2021/10/30 07:16:36 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs\n>>>   2021/10/30 07:16:36 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs/tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d\n>>>   2021/10/30 07:16:36 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs/tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d/55_azureml-execution-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\n>>>   2021/10/30 07:16:36 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a\n>>>   2021/10/30 07:16:36 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs\n>>>   2021/10/30 07:16:36 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs\n>>>   2021/10/30 07:16:36 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs\n>>>   2021/10/30 07:16:36 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs/tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d\n>>>   2021/10/30 07:16:36 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs/tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d/55_azureml-execution-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\n>>>   2021/10/30 07:16:36 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs\n>>>   2021/10/30 07:16:36 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/logs\n>>>   2021/10/30 07:16:36 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/outputs\n>>>   2021/10/30 07:16:36 Starting output-watcher...\n>>>   2021/10/30 07:16:36 Single file input dataset is enabled.\n>>>   2021/10/30 07:16:36 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n>>>   2021/10/30 07:16:36 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n>>>   2021/10/30 07:16:36 SidecarEnabled:: sidecar not enabled\n>>>   2021/10/30 07:16:36 Start to pulling docker image: mlcontainerregi222.azurecr.io/azureml/azureml_dded69baa6f866c564c25bc60667a4a7\n>>>   2021/10/30 07:16:36 Start pull docker image: mlcontainerregi222.azurecr.io\n>>>   2021/10/30 07:16:36 Getting credentials for image mlcontainerregi222.azurecr.io/azureml/azureml_dded69baa6f866c564c25bc60667a4a7 with url mlcontainerregi222.azurecr.io\n>>>   2021/10/30 07:16:36 Container registry is ACR.\n>>>   2021/10/30 07:16:36 Skip getting ACR Credentials from Identity and will be getting it from EMS\n>>>   2021/10/30 07:16:36 Getting ACR Credentials from EMS for environment keras-2.3.1:1\n>>>   2021/10/30 07:16:36 Requesting XDS for registry details.\n>>>   2021/10/30 07:16:36 Attempt 1 of http call to https://eastus.cert.api.azureml.ms/xdsbatchai/hosttoolapi/subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourceGroups/mlrg/workspaces/mlrgeast/clusters/cpu-cluster/nodes/tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d?api-version=2018-02-01\n>>>   2021/10/30 07:16:36 Got container registry details from credentials service for registry address: mlcontainerregi222.azurecr.io.\n>>>   2021/10/30 07:16:36 Writing ACR Details to file...\n>>>   2021/10/30 07:16:36 Copying ACR Details file to worker nodes...\n>>>   2021/10/30 07:16:36 Executing 'Copy ACR Details file' on 10.0.0.4\n>>>   2021/10/30 07:16:36 Begin executing 'Copy ACR Details file' task on Node\n>>>   2021/10/30 07:16:36 'Copy ACR Details file' task Node result: succeeded\n>>>   2021/10/30 07:16:36 Copy ACR Details file succeeded on 10.0.0.4. Output: \n>>>   >>>   \n>>>   >>>   \n>>>   2021/10/30 07:16:36 Successfully retrieved ACR Credentials from EMS.\n>>>   2021/10/30 07:16:36 EMS returned mlcontainerregi222.azurecr.io for environment keras-2.3.1\n>>>   2021/10/30 07:16:36 Save docker credentials for image mlcontainerregi222.azurecr.io/azureml/azureml_dded69baa6f866c564c25bc60667a4a7 in /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/docker_login_0F5B538E46BB3E55\n>>>   2021/10/30 07:16:36 Start login to the docker registry\n>>>   2021/10/30 07:16:36 Successfully logged into the docker registry.\n>>>   2021/10/30 07:16:36 Start run pull docker image command\n>>>   2021/10/30 07:16:36 Pull docker image succeeded.\n>>>   2021/10/30 07:16:36 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/docker_login_0F5B538E46BB3E55\n>>>   2021/10/30 07:16:36 Pull docker image time: 353.672869ms\n>>>   \n>>>   2021/10/30 07:16:36 Docker Version that this nodes use are: 19.03.14+azure\n>>>   \n>>>   2021/10/30 07:16:36 The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/30 07:16:36 The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/30 07:16:36 Setting the memory limit for docker container to be 13674 MB\n>>>   2021/10/30 07:16:36 The env variable file size is 38870 bytes\n>>>   2021/10/30 07:16:36 Creating parent cgroup 'myexp_1635578180_f782f42a' for Containers used in Job\n>>>   2021/10/30 07:16:36 Add parent cgroup 'myexp_1635578180_f782f42a' to container 'myexp_1635578180_f782f42a'\n>>>   2021/10/30 07:16:36 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n>>>   2021/10/30 07:16:36 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,myexp_1635578180_f782f42a,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/certs:/mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13674m,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/wd:/mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a:/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/myexp_1635578180_f782f42a/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/myexp_1635578180_f782f42a/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/config/.batchai.envlist,--cgroup-parent=/myexp_1635578180_f782f42a/,--shm-size,2g\n>>>   2021/10/30 07:16:36 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/myexp_1635578180_f782f42a/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/myexp_1635578180_f782f42a/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n>>>   2021/10/30 07:16:36 the binding /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a:/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a \n>>>   2021/10/30 07:16:36 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,myexp_1635578180_f782f42a,-m,13674m,-w,/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/config/.batchai.envlist,--cgroup-parent=/myexp_1635578180_f782f42a/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a:/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a,-v,/mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/wd:/mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/wd,-v,/mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/certs:/mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/certs\n>>>   2021/10/30 07:16:36 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name myexp_1635578180_f782f42a -m 13674m -w /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/config/.batchai.envlist --cgroup-parent=/myexp_1635578180_f782f42a/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a:/mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a -v /mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/wd:/mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/wd -v /mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/certs:/mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/certs -d -it --privileged --net=host mlcontainerregi222.azurecr.io/azureml/azureml_dded69baa6f866c564c25bc60667a4a7\n>>>   2021/10/30 07:16:36 Check if container myexp_1635578180_f782f42a already exist exited with 0, \n>>>   \n>>>   2021/10/30 07:16:36 Check if container myexp_1635578180_f782f42a already exist exited with 0, \n>>>   \n>>>   2021/10/30 07:16:37 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n>>>   2021/10/30 07:16:37 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n>>>   2021/10/30 07:16:37 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-31ea1d45b66e5f85d986b98a0b13d1ea-94f5cad182b9f82d-01 -sshRequired=false] \n>>>   2021/10/30 07:16:37 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-31ea1d45b66e5f85d986b98a0b13d1ea-94f5cad182b9f82d-01 -sshRequired=false] \n>>>   2021/10/30 07:16:37 Container ssh is not required for job type.\n>>>   2021/10/30 07:16:37 Starting docker container succeeded.\n>>>   2021/10/30 07:16:37 Starting docker container succeeded.\n>>>   2021/10/30 07:16:37 Disk space after starting docker container: 91778MB\n>>>   2021/10/30 07:16:37 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true\n>>>   2021/10/30 07:16:37 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false\n>>>   2021/10/30 07:16:37 SidecarEnabled:: sidecar not enabled\n>>>   2021/10/30 07:16:37 Begin execution of runSpecialJobTask\n>>>   2021/10/30 07:16:37 Creating directory at $AZUREML_LOGDIRECTORY_PATH\n>>>   2021/10/30 07:16:37 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml-logs\n>>>   2021/10/30 07:16:37 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs\n>>>   2021/10/30 07:16:37 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts/workspaceblobstore/azureml/myExp_1635578180_f782f42a-setup/job_prep.py --snapshots '[{\"Id\":\"5671372d-58d1-43c8-b425-5ed854c15325\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n>>>   2021/10/30 07:16:37 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs/65_job_prep-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\n>>>   2021/10/30 07:16:37 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a/azureml_compute_logs/65_job_prep-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\n>>>   2021/10/30 07:16:37 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a;/azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts/workspaceblobstore/azureml/myExp_1635578180_f782f42a-setup/job_prep.py --snapshots '[{\"Id\":\"5671372d-58d1-43c8-b425-5ed854c15325\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n>>>   2021/10/30 07:16:37 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n>>>   2021/10/30 07:16:37 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-31ea1d45b66e5f85d986b98a0b13d1ea-f99675b78d50a8e2-01 -t myexp_1635578180_f782f42a bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/bce7668d-12e1-4611-b966-2e8eadc678a9/job-1/myexp_1635578180_f78_fc7c13b6-490f-4800-a620-52b63c5ee86e/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/wd/azureml/myExp_1635578180_f782f42a;/azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/bin/python /mnt/batch/tasks/shared/LS_root/jobs/mlrgeast/azureml/myexp_1635578180_f782f42a/mounts/workspaceblobstore/azureml/myExp_1635578180_f782f42a-setup/job_prep.py --snapshots '[{\"Id\":\"5671372d-58d1-43c8-b425-5ed854c15325\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n>>>   2021/10/30 07:16:40 containerName:myexp_1635578180_f782f42a\n>>>   2021/10/30 07:16:40 sidecar containerName:myexp_1635578180_f782f42a\n>>>   2021/10/30 07:16:40 Docker Version that this nodes use are: 19.03.14+azure\n>>>   \n>>>   2021/10/30 07:16:40 The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/30 07:16:40 The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/30 07:16:40 sidecar dockerLauncher:docker\n>>>   2021/10/30 07:16:40 sidecarContainerId:f563e705aa9e8056f60321ae673ff8a0b9d6018f0f6cf14ad95d9c7971808ca6\n>>>   2021/10/30 07:16:40 Docker Version that this nodes use are: 19.03.14+azure\n>>>   \n>>>   2021/10/30 07:16:40 The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/30 07:16:40 The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n>>>   2021/10/30 07:16:40 Docker logs for myexp_1635578180_f782f42a\n>>>   bash: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so.5: no version information available (required by bash)\n>>>   \n>>>   2021/10/30 07:16:40 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n>>>   \n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: bash: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so.5: no version information available (required by bash)\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:38.185986] Entering job preparation.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:39.570150] Starting job preparation.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:39.570212] Extracting the control code.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:39.570886] Starting extract_project.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:39.570962] Starting to extract zip file.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:39.589429] Finished extracting zip file.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:39.593486] Using urllib.request Python 3.0 or later\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:39.593532] Start fetching snapshots.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:39.593598] Start fetching snapshot.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:39.593616] Retrieving project from snapshot: 5671372d-58d1-43c8-b425-5ed854c15325\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 44\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:40.054175] Finished fetching snapshot.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:40.054219] Finished fetching snapshots.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:40.054237] Finished extract_project.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:40.054348] Finished fetching and extracting the control code.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:40.059499] downloadDataStore - Download from datastores if requested.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:40.060318] Start run_history_prep.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:40.073606] Entering context manager injector.\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:40.078390] downloadDataStore completed\n>>>   2021/10/30 07:16:40 runSpecialJobTask: preparation: [2021-10-30T07:16:40.079974] Job preparation is complete.\n>>>   2021/10/30 07:16:40 DockerSideCarContainerLogs:\n>>>   bash: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so.5: no version information available (required by bash)\n>>>   \n>>>   2021/10/30 07:16:40 DockerSideCarContainerLogs End\n>>>   2021/10/30 07:16:40 Execution of runSpecialJobTask completed\n>>>   2021/10/30 07:16:40 Attempt 1 of http call to https://eastus.api.azureml.ms/history/v1.0/private/subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourceGroups/mlrg/providers/Microsoft.MachineLearningServices/workspaces/mlrgeast/runs/myExp_1635578180_f782f42a/spans\n>>>   2021/10/30 07:16:40 Process Exiting with Code:  0\n>>>   2021/10/30 07:16:41 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n>>>   \n2021-10-30T07:16:41Z The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-30T07:16:41Z The vmsize standard_d11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-10-30T07:16:41Z 127.0.0.1 slots=2 max-slots=2\n2021-10-30T07:16:41Z launching Custom job\n\nStreaming azureml-logs/75_job_post-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt\n===============================================================================================================\n\nbash: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so.5: no version information available (required by bash)\n[2021-10-30T07:16:56.729551] Entering job release\n[2021-10-30T07:16:57.782372] Starting job release\n[2021-10-30T07:16:57.783207] Logging experiment finalizing status in history service.\nStarting the daemon thread to refresh tokens in background for process with pid = 175\n[2021-10-30T07:16:57.783804] job release stage : upload_datastore starting...\n[2021-10-30T07:16:57.792750] job release stage : start importing azureml.history._tracking in run_history_release.\n[2021-10-30T07:16:57.793545] Entering context manager injector.\n[2021-10-30T07:16:57.794520] job release stage : execute_job_release starting...\n[2021-10-30T07:16:57.794923] job release stage : copy_batchai_cached_logs starting...\n[2021-10-30T07:16:57.795120] job release stage : copy_batchai_cached_logs completed...\n[2021-10-30T07:16:57.796435] job release stage : upload_datastore completed...\n[2021-10-30T07:16:57.874561] job release stage : send_run_telemetry starting...\n[2021-10-30T07:16:57.899814] get vm size and vm region successfully.\n[2021-10-30T07:16:57.915490] get compute meta data successfully.\n[2021-10-30T07:16:58.032180] job release stage : execute_job_release completed...\n[2021-10-30T07:16:58.149386] post artifact meta request successfully.\n[2021-10-30T07:16:58.189816] upload compute record artifact successfully.\n[2021-10-30T07:16:58.189910] job release stage : send_run_telemetry completed...\n[2021-10-30T07:16:58.190227] Job release is complete\n\nExecution Summary\n=================\nRunId: myExp_1635578180_f782f42a\nWeb View: https://ml.azure.com/runs/myExp_1635578180_f782f42a?wsid=/subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourcegroups/mlrg/workspaces/mlrgeast&tid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "{'runId': 'myExp_1635578180_f782f42a',\n 'target': 'cpu-cluster',\n 'status': 'Completed',\n 'startTimeUtc': '2021-10-30T07:16:34.624459Z',\n 'endTimeUtc': '2021-10-30T07:17:11.173537Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n  'ContentSnapshotId': '5671372d-58d1-43c8-b425-5ed854c15325',\n  'ProcessInfoFile': 'azureml-logs/process_info.json',\n  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'myModel.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': ['--data-folder',\n   '--batch-size',\n   '4',\n   '--first-layer-neurons',\n   '1024',\n   '--second-layer-neurons',\n   '500',\n   '--third-layer-neurons',\n   '300',\n   '--forth-layer-neurons',\n   '200',\n   '--learning-rate',\n   '0.001'],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'cpu-cluster',\n  'dataReferences': {},\n  'data': {},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'keras-2.3.1',\n   'version': '1',\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'channels': ['conda-forge'],\n     'dependencies': ['python=3.6.2',\n      {'pip': ['h5py<=2.10.0',\n        'azureml-defaults',\n        'tensorflow-gpu==2.0.0',\n        'keras<=2.3.1',\n        'matplotlib',\n        'pandas',\n        'scikit-learn']}],\n     'name': 'azureml_a8a0845f249cc373e9e7168f4f641be5'},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True}},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': 'pytorch-1.7.0',\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': False,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt': 'https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/azureml-logs/55_azureml-execution-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt?sv=2019-07-07&sr=b&sig=t0K95Gx1vyCSZqXQzhz8Wy3b%2F2mHWpueqw%2FXbW%2ByaDM%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T07%3A07%3A00Z&se=2021-10-30T15%3A17%3A00Z&sp=r',\n  'azureml-logs/65_job_prep-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt': 'https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/azureml-logs/65_job_prep-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt?sv=2019-07-07&sr=b&sig=Y%2FptxsjHON4R8hCpltyK8Azcgr%2F3XhWSDWkTvrtCeNQ%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T07%3A07%3A00Z&se=2021-10-30T15%3A17%3A00Z&sp=r',\n  'azureml-logs/70_driver_log.txt': 'https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=lV%2F%2BR%2F5a10iNmLHDqtu4fq%2BbcW3iTFH72UeT0lWcZ4w%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T07%3A07%3A00Z&se=2021-10-30T15%3A17%3A00Z&sp=r',\n  'azureml-logs/75_job_post-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt': 'https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/azureml-logs/75_job_post-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt?sv=2019-07-07&sr=b&sig=dzqpyt49cvTgB%2BrD1WeZ76ht5r6BWSA1DRqzy4KzciA%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T07%3A07%3A00Z&se=2021-10-30T15%3A17%3A00Z&sp=r',\n  'azureml-logs/process_info.json': 'https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=xAQfFyqQT8CwtTeGeiFaJrL9p%2FA5wuijAfisSOWhjrk%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T07%3A07%3A00Z&se=2021-10-30T15%3A17%3A00Z&sp=r',\n  'azureml-logs/process_status.json': 'https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=%2Fp1UqU09d9hMPNu77xOkxOa2QC5IZxTjKLhSUZA7fw4%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T07%3A07%3A00Z&se=2021-10-30T15%3A17%3A00Z&sp=r',\n  'logs/azureml/94_azureml.log': 'https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/logs/azureml/94_azureml.log?sv=2019-07-07&sr=b&sig=5q37Hvzfa3M%2BIWyhSjqTJcdU8JTIuf8QLsYWMEQWu6s%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T07%3A07%3A00Z&se=2021-10-30T15%3A17%3A00Z&sp=r',\n  'logs/azureml/job_prep_azureml.log': 'https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=76Xf7G1XkIenks0mrc7cXfXcUGsfxDN5JgLVxDc7WZc%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T07%3A07%3A00Z&se=2021-10-30T15%3A17%3A00Z&sp=r',\n  'logs/azureml/job_release_azureml.log': 'https://strageeastus222.blob.core.windows.net/azureml/ExperimentRun/dcid.myExp_1635578180_f782f42a/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=JUMmPRCmhslPOY7kRIE9ejwwCBEAnNA2RiM6fPXIjwI%3D&skoid=6656fe42-2b43-4eb4-8dfe-9e9ae0b4d827&sktid=19411b3a-b7ca-48d9-a1e2-31694d0ccb65&skt=2021-10-30T06%3A45%3A07Z&ske=2021-10-31T14%3A55%3A07Z&sks=b&skv=2019-07-07&st=2021-10-30T07%3A07%3A00Z&se=2021-10-30T15%3A17%3A00Z&sp=r'},\n 'submittedBy': 'jinkue Jeong'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635578234655
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(run.get_metrics())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'Final test loss(mse)': 0.36707951805808325, 'Final test loss(mae)': 0.5233289003372192, 'loss VS val_loss': 'aml://artifactId/ExperimentRun/dcid.myExp_1635578180_f782f42a/loss VS val_loss_1635578208.png'}\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635578282396
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(run.get_file_names())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['azureml-logs/55_azureml-execution-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt', 'azureml-logs/65_job_prep-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_a7962f7b2ac9f1169c87ceb6cae64816af463a4730631f356922b7709eaa65dc_d.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/94_azureml.log', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'loss VS val_loss_1635578208.png', 'outputs/Youjin_test_model.pkl']\n"
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635578283834
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 생성된 모델 등록"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''model = run.register_model(model_name='myModelYoujin2', model_path='.')'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635511979276
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\r\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\r\n",
        "\r\n",
        "model = run.register_model(model_name='Youjin-test', \r\n",
        "                           model_path='outputs/Youjin_test_model.pkl',\r\n",
        "                           model_framework=Model.Framework.TENSORFLOW,\r\n",
        "                           model_framework_version='2.0',\r\n",
        "                           )\r\n",
        "\r\n",
        "print(model.name, model.id, model.version, sep='\\t')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Youjin-test\tYoujin-test:1\t1\n"
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635578287351
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''os.makedirs('./model', exist_ok=True)\r\n",
        "\r\n",
        "for f in run.get_file_names():\r\n",
        "    if f.startswith('outputs/model'):\r\n",
        "        output_file_path = os.path.join('./model', f.split('/')[-1])\r\n",
        "        print('Downloading from {} to {} ...'.format(f, output_file_path))\r\n",
        "        run.download_file(name=f, output_file_path=output_file_path)'''"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635511980639
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}