{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/how-to-use-azureml/deployment/production-deploy-to-aks/production-deploy-to-aks.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploying a web service to Azure Kubernetes Service (AKS)\n",
        "This notebook shows the steps for deploying a service: registering a model, creating an image, provisioning a cluster (one time action), and deploying a service to it. \n",
        "We then test and delete the service, image and model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "from azureml.core.compute import AksCompute, ComputeTarget\n",
        "from azureml.core.webservice import Webservice, AksWebservice\n",
        "from azureml.core.model import Model"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1635578360526
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "print(azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1.34.0\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1635578362910
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get workspace\n",
        "Load existing workspace from the config file info."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "mlrgeast\nmlrg\neastus\n932c3e14-d0cf-4e41-9998-bdebb9bfa1cf\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1635578367158
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Register the model\n",
        "Register an existing trained model, add descirption and tags."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Register the model\n",
        "from azureml.core.model import Model\n",
        "\n",
        "model_name = \"Youjin-test\"\n",
        "'''model = Model.register( model_path='./',\n",
        "                        model_name=modelname,\n",
        "                        tags={\"data\": \"mosquito\", \"model\": \"regression\"},\n",
        "                        description=\"predict mosquito status\",\n",
        "                        workspace=ws)'''\n",
        "\n",
        "\n",
        "model = Model(ws, model_name,version=1)\n",
        "print(model.name, model.description, model.version)\n",
        "#print(str(Model.get_model_path('myModelYoujin', 1, ws)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Youjin-test None 1\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1635578371820
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Model.get_model_path(model_name,1,ws))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "azureml-models/Youjin-test/1/Youjin_test_model.pkl\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635578373776
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Environment\n",
        "Create an environment that the model will be deployed with"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies \n",
        "'''\n",
        "conda_deps = CondaDependencies.create(conda_packages=['numpy','tensorflow==1.12.0','scipy'], pip_packages=['azureml-defaults', 'inference-schema'])\n",
        "myenv = Environment(name='myExp')\n",
        "myenv.python.conda_dependencies = conda_deps'''\n",
        "\n",
        "from azureml.core import Environment\n",
        "\n",
        "env = Environment.from_conda_specification(name = 'keras-2.3.1', file_path = './conda_dependencies.yml')\n",
        "\n",
        "'''# Specify a GPU base image\n",
        "env.docker.enabled = True\n",
        "env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.0-cudnn7-ubuntu18.04'''\n",
        "\n",
        "env.register(workspace = ws)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "{\n    \"databricks\": {\n        \"eggLibraries\": [],\n        \"jarLibraries\": [],\n        \"mavenLibraries\": [],\n        \"pypiLibraries\": [],\n        \"rcranLibraries\": []\n    },\n    \"docker\": {\n        \"arguments\": [],\n        \"baseDockerfile\": null,\n        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210806.v1\",\n        \"baseImageRegistry\": {\n            \"address\": null,\n            \"password\": null,\n            \"registryIdentity\": null,\n            \"username\": null\n        },\n        \"enabled\": false,\n        \"platform\": {\n            \"architecture\": \"amd64\",\n            \"os\": \"Linux\"\n        },\n        \"sharedVolumes\": true,\n        \"shmSize\": null\n    },\n    \"environmentVariables\": {\n        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n    },\n    \"inferencingStackVersion\": null,\n    \"name\": \"keras-2.3.1\",\n    \"python\": {\n        \"baseCondaEnvironment\": null,\n        \"condaDependencies\": {\n            \"channels\": [\n                \"conda-forge\"\n            ],\n            \"dependencies\": [\n                \"python=3.6.2\",\n                {\n                    \"pip\": [\n                        \"h5py<=2.10.0\",\n                        \"azureml-defaults\",\n                        \"tensorflow-gpu==2.0.0\",\n                        \"keras<=2.3.1\",\n                        \"matplotlib\",\n                        \"pandas\",\n                        \"scikit-learn\"\n                    ]\n                }\n            ],\n            \"name\": \"azureml_a8a0845f249cc373e9e7168f4f641be5\"\n        },\n        \"condaDependenciesFile\": null,\n        \"interpreterPath\": \"python\",\n        \"userManagedDependencies\": false\n    },\n    \"r\": null,\n    \"spark\": {\n        \"packages\": [],\n        \"precachePackages\": true,\n        \"repositories\": []\n    },\n    \"version\": \"1\"\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1635578377494
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''from azureml.core import Environment\r\n",
        "\r\n",
        "keras_env = Environment.from_conda_specification(name = 'keras-2.3.1', file_path = './conda_dependencies.yml')\r\n",
        "\r\n",
        "myenv = Environment(name='myExp')\r\n",
        "myenv.python.conda_dependencies = keras_env'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "\"from azureml.core import Environment\\n\\nkeras_env = Environment.from_conda_specification(name = 'keras-2.3.1', file_path = './conda_dependencies.yml')\\n\\nmyenv = Environment(name='myExp')\\nmyenv.python.conda_dependencies = keras_env\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635512329924
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use a custom Docker image\n",
        "\n",
        "You can also specify a custom Docker image to be used as base image if you don't want to use the default base image provided by Azure ML. Please make sure the custom Docker image has Ubuntu >= 16.04, Conda >= 4.5.\\* and Python(3.5.\\* or 3.6.\\*).\n",
        "\n",
        "Only supported with `python` runtime.\n",
        "```python\n",
        "# use an image available in public Container Registry without authentication\n",
        "myenv.docker.base_image = \"mcr.microsoft.com/azureml/o16n-sample-user-base/ubuntu-miniconda\"\n",
        "\n",
        "# or, use an image available in a private Container Registry\n",
        "myenv.docker.base_image = \"myregistry.azurecr.io/mycustomimage:1.0\"\n",
        "myenv.docker.base_image_registry.address = \"myregistry.azurecr.io\"\n",
        "myenv.docker.base_image_registry.username = \"username\"\n",
        "myenv.docker.base_image_registry.password = \"password\"\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write the Entry Script\n",
        "Write the script that will be used to predict on your model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile score.py\n",
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import numpy\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    #model_path=os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'Youjin_test')\n",
        "    model = joblib.load('azureml-models/Youjin-test/1/Youjin_test_model.pkl')\n",
        "    history = model.fit(x_train, y_train, epochs=eph_size, batch_size=4,validation_data=(x_val,y_val))\n",
        "    score = model.evaluate(x_test, y_test)\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
        "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
        "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
        "    \n",
        "    #model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'myModelYoujin')\n",
        "    # deserialize the model file back into a sklearn model\n",
        "   #model_path = os.path.join('./model', 'myModelYoujin')\n",
        "   # model = joblib.load(model_path)\n",
        "\n",
        "# note you can pass in multiple rows for scoring\n",
        "def run(raw_data):\n",
        "    try:\n",
        "        input_json = {'data': [[20.5, 18.1, 23.1, 2.3, 93.3, 82.0],\n",
        "                        [23.7, 21.9, 26.3, 1.6, 82.6, 79.3]]}\n",
        "    # create a string that can be put in the body of the request\n",
        "        data = json.dumps(input_json)\n",
        "        data = numpy.array(data)\n",
        "        result = model.predict(data)\n",
        "        # you can return any data type as long as it is JSON-serializable\n",
        "        return result.tolist()\n",
        "    except Exception as e:\n",
        "        error = str(e)\n",
        "        return error"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting score.py\n"
        }
      ],
      "execution_count": 35,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the InferenceConfig\n",
        "Create the inference config that will be used when deploying the model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "inf_config = InferenceConfig(entry_script='score.py', environment=env)"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1635582171316
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''from azureml.core.model import InferenceConfig\r\n",
        "from azureml.core.webservice import AciWebservice\r\n",
        "\r\n",
        "\r\n",
        "service_name = 'youjin-deploy-test'\r\n",
        "\r\n",
        "inference_config = InferenceConfig(entry_script='score.py', environment=myenv)\r\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\r\n",
        "\r\n",
        "service = Model.deploy(workspace=ws,\r\n",
        "                       name=service_name,\r\n",
        "                       models=[model],\r\n",
        "                       inference_config=inference_config,\r\n",
        "                       deployment_config=aci_config,\r\n",
        "                       overwrite=True)\r\n",
        "service.wait_for_deployment(show_output=True)'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "\"from azureml.core.model import InferenceConfig\\nfrom azureml.core.webservice import AciWebservice\\n\\n\\nservice_name = 'youjin-deploy-test'\\n\\ninference_config = InferenceConfig(entry_script='score.py', environment=myenv)\\naci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\\n\\nservice = Model.deploy(workspace=ws,\\n                       name=service_name,\\n                       models=[model],\\n                       inference_config=inference_config,\\n                       deployment_config=aci_config,\\n                       overwrite=True)\\nservice.wait_for_deployment(show_output=True)\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635512331915
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Profiling\n",
        "\n",
        "Profile your model to understand how much CPU and memory the service, created as a result of its deployment, will need. Profiling returns information such as CPU usage, memory usage, and response latency. It also provides a CPU and memory recommendation based on the resource usage. You can profile your model (or more precisely the service built based on your model) on any CPU and/or memory combination where 0.1 <= CPU <= 3.5 and 0.1GB <= memory <= 15GB. If you do not provide a CPU and/or memory requirement, we will test it on the default configuration of 3.5 CPU and 15GB memory.\n",
        "\n",
        "In order to profile your model you will need:\n",
        "- a registered model\n",
        "- an entry script\n",
        "- an inference configuration\n",
        "- a single column tabular dataset, where each row contains a string representing sample request data sent to the service.\n",
        "\n",
        "Please, note that profiling is a long running operation and can take up to 25 minutes depending on the size of the dataset.\n",
        "\n",
        "At this point we only support profiling of services that expect their request data to be a string, for example: string serialized json, text, string serialized image, etc. The content of each row of the dataset (string) will be put into the body of the HTTP request and sent to the service encapsulating the model for scoring.\n",
        "\n",
        "Below is an example of how you can construct an input dataset to profile a service which expects its incoming requests to contain serialized json. In this case we created a dataset based one hundred instances of the same request data. In real world scenarios however, we suggest that you use larger datasets with various inputs, especially if your model resource usage/behavior is input dependent."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may want to register datasets using the register() method to your workspace so they can be shared with others, reused and referred to by name in your script.\n",
        "You can try get the dataset first to see if it's already registered."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "'''import json\n",
        "from azureml.core import Datastore\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.data import dataset_type_definitions\n",
        "\n",
        "dataset_name='sample_request_data'\n",
        "\n",
        "dataset_registered = False\n",
        "try:\n",
        "    sample_request_data = Dataset.get_by_name(workspace = ws, name = dataset_name)\n",
        "    dataset_registered = True\n",
        "except:\n",
        "    print(\"The dataset {} is not registered in workspace yet.\".format(dataset_name))\n",
        "\n",
        "if not dataset_registered:\n",
        "    input_json = {'data': [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "                        [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]]}\n",
        "    # create a string that can be put in the body of the request\n",
        "    serialized_input_json = json.dumps(input_json)\n",
        "    dataset_content = []\n",
        "    for i in range(100):\n",
        "        dataset_content.append(serialized_input_json)\n",
        "    sample_request_data = '\\n'.join(dataset_content)\n",
        "    file_name = \"{}.txt\".format(dataset_name)\n",
        "    f = open(file_name, 'w')\n",
        "    f.write(sample_request_data)\n",
        "    f.close()\n",
        "\n",
        "    # upload the txt file created above to the Datastore and create a dataset from it\n",
        "    data_store = Datastore.get_default(ws)\n",
        "    data_store.upload_files(['./' + file_name], target_path='sample_request_data')\n",
        "    datastore_path = [(data_store, 'sample_request_data' +'/' + file_name)]\n",
        "    sample_request_data = Dataset.Tabular.from_delimited_files(\n",
        "        datastore_path,\n",
        "        separator='\\n',\n",
        "        infer_column_types=True,\n",
        "        header=dataset_type_definitions.PromoteHeadersBehavior.NO_HEADERS)\n",
        "    sample_request_data = sample_request_data.register(workspace=ws,\n",
        "                                                    name=dataset_name,\n",
        "                                                    create_new_version=True)'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "'import json\\nfrom azureml.core import Datastore\\nfrom azureml.core.dataset import Dataset\\nfrom azureml.data import dataset_type_definitions\\n\\ndataset_name=\\'sample_request_data\\'\\n\\ndataset_registered = False\\ntry:\\n    sample_request_data = Dataset.get_by_name(workspace = ws, name = dataset_name)\\n    dataset_registered = True\\nexcept:\\n    print(\"The dataset {} is not registered in workspace yet.\".format(dataset_name))\\n\\nif not dataset_registered:\\n    input_json = {\\'data\\': [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\\n                        [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]]}\\n    # create a string that can be put in the body of the request\\n    serialized_input_json = json.dumps(input_json)\\n    dataset_content = []\\n    for i in range(100):\\n        dataset_content.append(serialized_input_json)\\n    sample_request_data = \\'\\n\\'.join(dataset_content)\\n    file_name = \"{}.txt\".format(dataset_name)\\n    f = open(file_name, \\'w\\')\\n    f.write(sample_request_data)\\n    f.close()\\n\\n    # upload the txt file created above to the Datastore and create a dataset from it\\n    data_store = Datastore.get_default(ws)\\n    data_store.upload_files([\\'./\\' + file_name], target_path=\\'sample_request_data\\')\\n    datastore_path = [(data_store, \\'sample_request_data\\' +\\'/\\' + file_name)]\\n    sample_request_data = Dataset.Tabular.from_delimited_files(\\n        datastore_path,\\n        separator=\\'\\n\\',\\n        infer_column_types=True,\\n        header=dataset_type_definitions.PromoteHeadersBehavior.NO_HEADERS)\\n    sample_request_data = sample_request_data.register(workspace=ws,\\n                                                    name=dataset_name,\\n                                                    create_new_version=True)'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1635512332385
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have an input dataset we are ready to go ahead with profiling. In this case we are testing the previously introduced sklearn regression model on 1 CPU and 0.5 GB memory. The memory usage and recommendation presented in the result is measured in Gigabytes. The CPU usage and recommendation is measured in CPU cores."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "'''from datetime import datetime\n",
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.model import Model, InferenceConfig\n",
        "\n",
        "\n",
        "environment = Environment('my-sklearn-environment')\n",
        "environment.python.conda_dependencies = CondaDependencies.create(pip_packages=[\n",
        "    'azureml-defaults',\n",
        "    'inference-schema[numpy-support]',\n",
        "    'joblib',\n",
        "    'numpy',\n",
        "    'scikit-learn==0.19.1',\n",
        "    'scipy'\n",
        "])\n",
        "inference_config = InferenceConfig(entry_script='score.py', environment=environment)\n",
        "# if cpu and memory_in_gb parameters are not provided\n",
        "# the model will be profiled on default configuration of\n",
        "# 3.5CPU and 15GB memory\n",
        "profile = Model.profile(ws,\n",
        "            'sklearn-%s' % datetime.now().strftime('%m%d%Y-%H%M%S'),\n",
        "            [model],\n",
        "            inference_config,\n",
        "            input_dataset=sample_request_data,\n",
        "            cpu=1.0,\n",
        "            memory_in_gb=0.5)\n",
        "\n",
        "# profiling is a long running operation and may take up to 25 min\n",
        "profile.wait_for_completion(True)\n",
        "details = profile.get_details()'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "\"from datetime import datetime\\nfrom azureml.core import Environment\\nfrom azureml.core.conda_dependencies import CondaDependencies\\nfrom azureml.core.model import Model, InferenceConfig\\n\\n\\nenvironment = Environment('my-sklearn-environment')\\nenvironment.python.conda_dependencies = CondaDependencies.create(pip_packages=[\\n    'azureml-defaults',\\n    'inference-schema[numpy-support]',\\n    'joblib',\\n    'numpy',\\n    'scikit-learn==0.19.1',\\n    'scipy'\\n])\\ninference_config = InferenceConfig(entry_script='score.py', environment=environment)\\n# if cpu and memory_in_gb parameters are not provided\\n# the model will be profiled on default configuration of\\n# 3.5CPU and 15GB memory\\nprofile = Model.profile(ws,\\n            'sklearn-%s' % datetime.now().strftime('%m%d%Y-%H%M%S'),\\n            [model],\\n            inference_config,\\n            input_dataset=sample_request_data,\\n            cpu=1.0,\\n            memory_in_gb=0.5)\\n\\n# profiling is a long running operation and may take up to 25 min\\nprofile.wait_for_completion(True)\\ndetails = profile.get_details()\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1635512333006
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Provision the AKS Cluster\n",
        "This is a one time setup. You can reuse this cluster for multiple deployments after it has been created. If you delete the cluster or the resource group that contains it, then you would have to recreate it.\n",
        "\n",
        "> Note that if you have an AzureML Data Scientist role, you will not have permission to create compute resources. Talk to your workspace or IT admin to create the compute targets described in this section, if they do not already exist."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Choose a name for your AKS cluster\n",
        "aks_name = 'my-aks-9' \n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # Use the default configuration (can also provide parameters to customize)\n",
        "    prov_config = AksCompute.provisioning_configuration(vm_size='STANDARD_D11_V2', location='East US')\n",
        "\n",
        "    # Create the cluster\n",
        "    aks_target = ComputeTarget.create(workspace = ws, \n",
        "                                    name = aks_name, \n",
        "                                    provisioning_configuration = prov_config)\n",
        "\n",
        "if aks_target.get_status() != \"Succeeded\":\n",
        "    aks_target.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1635582219458
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create AKS Cluster in an existing virtual network (optional)\n",
        "See code snippet below. Check the documentation [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-enable-virtual-network#use-azure-kubernetes-service) for more details."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# from azureml.core.compute import ComputeTarget, AksCompute\n",
        "\n",
        "# # Create the compute configuration and set virtual network information\n",
        "# config = AksCompute.provisioning_configuration(location=\"eastus2\")\n",
        "# config.vnet_resourcegroup_name = \"mygroup\"\n",
        "# config.vnet_name = \"mynetwork\"\n",
        "# config.subnet_name = \"default\"\n",
        "# config.service_cidr = \"10.0.0.0/16\"\n",
        "# config.dns_service_ip = \"10.0.0.10\"\n",
        "# config.docker_bridge_cidr = \"172.17.0.1/16\"\n",
        "\n",
        "# # Create the compute target\n",
        "# aks_target = ComputeTarget.create(workspace = ws,\n",
        "#                                   name = \"myaks\",\n",
        "#                                   provisioning_configuration = config)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1635512334430
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enable SSL on the AKS Cluster (optional)\n",
        "See code snippet below. Check the documentation [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-secure-web-service) for more details"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# provisioning_config = AksCompute.provisioning_configuration(ssl_cert_pem_file=\"cert.pem\", ssl_key_pem_file=\"key.pem\", ssl_cname=\"www.contoso.com\")"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1635512335006
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''%%time\n",
        "aks_target.wait_for_completion(show_output = True)\n",
        "print(aks_target.provisioning_state)\n",
        "print(aks_target.provisioning_errors)'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "'%%time\\naks_target.wait_for_completion(show_output = True)\\nprint(aks_target.provisioning_state)\\nprint(aks_target.provisioning_errors)'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1635512335510
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional step: Attach existing AKS cluster\n",
        "\n",
        "If you have existing AKS cluster in your Azure subscription, you can attach it to the Workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "'''# # Use the default configuration (can also provide parameters to customize)\n",
        "resourceid = '/subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourcegroups/MLRG/providers/Microsoft.ContainerService/managedClusters/youjin-aks3c41624805d'\n",
        "\n",
        "create_name='Youjin-aks-3'\n",
        "# # Create the cluster\n",
        "attach_config = AksCompute.attach_configuration(resource_id=resourceid)\n",
        "aks_target = ComputeTarget.attach(workspace=ws, name=create_name, attach_configuration=attach_config)\n",
        "# # Wait for the operation to complete\n",
        "aks_target.wait_for_completion(True)'''"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "\"# # Use the default configuration (can also provide parameters to customize)\\nresourceid = '/subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourcegroups/MLRG/providers/Microsoft.ContainerService/managedClusters/youjin-aks3c41624805d'\\n\\ncreate_name='Youjin-aks-3'\\n# # Create the cluster\\nattach_config = AksCompute.attach_configuration(resource_id=resourceid)\\naks_target = ComputeTarget.attach(workspace=ws, name=create_name, attach_configuration=attach_config)\\n# # Wait for the operation to complete\\naks_target.wait_for_completion(True)\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1635512336199
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy web service to AKS"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the web service configuration (using default here)\n",
        "#aks_config = AksWebservice.deploy_configuration()\n",
        "\n",
        "# # Enable token auth and disable (key) auth on the webservice\n",
        "aks_config = AksWebservice.deploy_configuration(token_auth_enabled=True, auth_enabled=False)\n"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "tags": [
          "sample-deploy-to-aks"
        ],
        "gather": {
          "logged": 1635582226649
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "aks_service_name ='aks-service-12'\n",
        "\n",
        "aks_service = Model.deploy(workspace=ws,\n",
        "                           name=aks_service_name,\n",
        "                           models=[model],\n",
        "                           inference_config=inf_config,\n",
        "                           deployment_config=aks_config,\n",
        "                           deployment_target=aks_target)\n",
        "\n",
        "aks_service.wait_for_deployment(show_output = True)\n",
        "print(aks_service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2021-10-30 08:40:06+00:00 Creating Container Registry if not exists.\n2021-10-30 08:40:07+00:00 Registering the environment.\n2021-10-30 08:40:08+00:00 Use the existing image.\n2021-10-30 08:40:09+00:00 Creating resources in AKS.\n2021-10-30 08:40:10+00:00 Submitting deployment to compute.\n2021-10-30 08:40:10+00:00 Checking the status of deployment aks-service-12.\nFailed\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "ERROR:azureml.core.webservice.webservice:Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: cf88c209-0f6e-4b1f-ad3e-acc12217afbe\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"KubernetesDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Kubernetes Deployment failed\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Error in entry script, AttributeError: 'NoneType' object has no attribute 'fit', please run print(service.get_logs()) to get details.\"\n    },\n    {\n      \"code\": \"DeploymentFailed\",\n      \"message\": \"Your container endpoint is not available. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. View the diagnostic events to check status of container, it may help you to debug the issue.\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Warning\",\"Reason\":\"FailedScheduling\",\"Message\":\"0/3 nodes are available: 3 pod has unbound immediate PersistentVolumeClaims.\",\"LastTimestamp\":\"2021-10-30T08:40:11Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Scheduled\",\"Message\":\"Successfully assigned azureml-mlrgeast/aks-service-12-696bc45d4c-gvcwn to aks-agentpool-38843976-vmss000002\",\"LastTimestamp\":\"2021-10-30T08:40:22Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Pulled\",\"Message\":\"Container image \"mcr.microsoft.com/azureml/dependency-unpacker:20210714\" already present on machine\",\"LastTimestamp\":\"2021-10-30T08:40:23Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Created\",\"Message\":\"Created container amlappinit\",\"LastTimestamp\":\"2021-10-30T08:40:23Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Started\",\"Message\":\"Started container amlappinit\",\"LastTimestamp\":\"2021-10-30T08:40:23Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Pulled\",\"Message\":\"Container image \"mlcontainerregi222.azurecr.io/azureml/azureml_dded69baa6f866c564c25bc60667a4a7\" already present on machine\",\"LastTimestamp\":\"2021-10-30T08:40:59Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Created\",\"Message\":\"Created container aks-service-12\",\"LastTimestamp\":\"2021-10-30T08:41:00Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Started\",\"Message\":\"Started container aks-service-12\",\"LastTimestamp\":\"2021-10-30T08:41:00Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Warning\",\"Reason\":\"Unhealthy\",\"Message\":\"Readiness probe failed: HTTP probe failed with statuscode: 502\",\"LastTimestamp\":\"2021-10-30T08:41:32Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Warning\",\"Reason\":\"BackOff\",\"Message\":\"Back-off restarting failed container\",\"LastTimestamp\":\"2021-10-30T08:41:38Z\"}\n\"\n    }\n  ]\n}\n\n"
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: cf88c209-0f6e-4b1f-ad3e-acc12217afbe\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"KubernetesDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Kubernetes Deployment failed\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Error in entry script, AttributeError: 'NoneType' object has no attribute 'fit', please run print(service.get_logs()) to get details.\"\n    },\n    {\n      \"code\": \"DeploymentFailed\",\n      \"message\": \"Your container endpoint is not available. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. View the diagnostic events to check status of container, it may help you to debug the issue.\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Warning\",\"Reason\":\"FailedScheduling\",\"Message\":\"0/3 nodes are available: 3 pod has unbound immediate PersistentVolumeClaims.\",\"LastTimestamp\":\"2021-10-30T08:40:11Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Scheduled\",\"Message\":\"Successfully assigned azureml-mlrgeast/aks-service-12-696bc45d4c-gvcwn to aks-agentpool-38843976-vmss000002\",\"LastTimestamp\":\"2021-10-30T08:40:22Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Pulled\",\"Message\":\"Container image \"mcr.microsoft.com/azureml/dependency-unpacker:20210714\" already present on machine\",\"LastTimestamp\":\"2021-10-30T08:40:23Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Created\",\"Message\":\"Created container amlappinit\",\"LastTimestamp\":\"2021-10-30T08:40:23Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Started\",\"Message\":\"Started container amlappinit\",\"LastTimestamp\":\"2021-10-30T08:40:23Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Pulled\",\"Message\":\"Container image \"mlcontainerregi222.azurecr.io/azureml/azureml_dded69baa6f866c564c25bc60667a4a7\" already present on machine\",\"LastTimestamp\":\"2021-10-30T08:40:59Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Created\",\"Message\":\"Created container aks-service-12\",\"LastTimestamp\":\"2021-10-30T08:41:00Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Started\",\"Message\":\"Started container aks-service-12\",\"LastTimestamp\":\"2021-10-30T08:41:00Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Warning\",\"Reason\":\"Unhealthy\",\"Message\":\"Readiness probe failed: HTTP probe failed with statuscode: 502\",\"LastTimestamp\":\"2021-10-30T08:41:32Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Warning\",\"Reason\":\"BackOff\",\"Message\":\"Back-off restarting failed container\",\"LastTimestamp\":\"2021-10-30T08:41:38Z\"}\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: cf88c209-0f6e-4b1f-ad3e-acc12217afbe\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"KubernetesDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Kubernetes Deployment failed\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Error in entry script, AttributeError: 'NoneType' object has no attribute 'fit', please run print(service.get_logs()) to get details.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"DeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container endpoint is not available. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. View the diagnostic events to check status of container, it may help you to debug the issue.\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Warning\\\",\\\"Reason\\\":\\\"FailedScheduling\\\",\\\"Message\\\":\\\"0/3 nodes are available: 3 pod has unbound immediate PersistentVolumeClaims.\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:40:11Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Scheduled\\\",\\\"Message\\\":\\\"Successfully assigned azureml-mlrgeast/aks-service-12-696bc45d4c-gvcwn to aks-agentpool-38843976-vmss000002\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:40:22Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Container image \\\"mcr.microsoft.com/azureml/dependency-unpacker:20210714\\\" already present on machine\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:40:23Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Created\\\",\\\"Message\\\":\\\"Created container amlappinit\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:40:23Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Started\\\",\\\"Message\\\":\\\"Started container amlappinit\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:40:23Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Container image \\\"mlcontainerregi222.azurecr.io/azureml/azureml_dded69baa6f866c564c25bc60667a4a7\\\" already present on machine\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:40:59Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Created\\\",\\\"Message\\\":\\\"Created container aks-service-12\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:41:00Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Started\\\",\\\"Message\\\":\\\"Started container aks-service-12\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:41:00Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Warning\\\",\\\"Reason\\\":\\\"Unhealthy\\\",\\\"Message\\\":\\\"Readiness probe failed: HTTP probe failed with statuscode: 502\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:41:32Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Warning\\\",\\\"Reason\\\":\\\"BackOff\\\",\\\"Message\\\":\\\"Back-off restarting failed container\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:41:38Z\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    923\u001b[0m                                           \u001b[0;34m'Error:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                                           '{}'.format(self.state, self._operation_endpoint.split('/')[-1],\n\u001b[0;32m--> 925\u001b[0;31m                                                       logs_response, format_error_response), logger=module_logger)\n\u001b[0m\u001b[1;32m    926\u001b[0m             print('{} service creation operation finished, operation \"{}\"'.format(self._webservice_type,\n\u001b[1;32m    927\u001b[0m                                                                                   operation_state))\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: cf88c209-0f6e-4b1f-ad3e-acc12217afbe\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"KubernetesDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Kubernetes Deployment failed\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Error in entry script, AttributeError: 'NoneType' object has no attribute 'fit', please run print(service.get_logs()) to get details.\"\n    },\n    {\n      \"code\": \"DeploymentFailed\",\n      \"message\": \"Your container endpoint is not available. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. View the diagnostic events to check status of container, it may help you to debug the issue.\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Warning\",\"Reason\":\"FailedScheduling\",\"Message\":\"0/3 nodes are available: 3 pod has unbound immediate PersistentVolumeClaims.\",\"LastTimestamp\":\"2021-10-30T08:40:11Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Scheduled\",\"Message\":\"Successfully assigned azureml-mlrgeast/aks-service-12-696bc45d4c-gvcwn to aks-agentpool-38843976-vmss000002\",\"LastTimestamp\":\"2021-10-30T08:40:22Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Pulled\",\"Message\":\"Container image \"mcr.microsoft.com/azureml/dependency-unpacker:20210714\" already present on machine\",\"LastTimestamp\":\"2021-10-30T08:40:23Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Created\",\"Message\":\"Created container amlappinit\",\"LastTimestamp\":\"2021-10-30T08:40:23Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Started\",\"Message\":\"Started container amlappinit\",\"LastTimestamp\":\"2021-10-30T08:40:23Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Pulled\",\"Message\":\"Container image \"mlcontainerregi222.azurecr.io/azureml/azureml_dded69baa6f866c564c25bc60667a4a7\" already present on machine\",\"LastTimestamp\":\"2021-10-30T08:40:59Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Created\",\"Message\":\"Created container aks-service-12\",\"LastTimestamp\":\"2021-10-30T08:41:00Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Normal\",\"Reason\":\"Started\",\"Message\":\"Started container aks-service-12\",\"LastTimestamp\":\"2021-10-30T08:41:00Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Warning\",\"Reason\":\"Unhealthy\",\"Message\":\"Readiness probe failed: HTTP probe failed with statuscode: 502\",\"LastTimestamp\":\"2021-10-30T08:41:32Z\"}\n{\"InvolvedObject\":\"aks-service-12-696bc45d4c-gvcwn\",\"InvolvedKind\":\"Pod\",\"Type\":\"Warning\",\"Reason\":\"BackOff\",\"Message\":\"Back-off restarting failed container\",\"LastTimestamp\":\"2021-10-30T08:41:38Z\"}\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: cf88c209-0f6e-4b1f-ad3e-acc12217afbe\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"KubernetesDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Kubernetes Deployment failed\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Error in entry script, AttributeError: 'NoneType' object has no attribute 'fit', please run print(service.get_logs()) to get details.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"DeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container endpoint is not available. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. View the diagnostic events to check status of container, it may help you to debug the issue.\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Warning\\\",\\\"Reason\\\":\\\"FailedScheduling\\\",\\\"Message\\\":\\\"0/3 nodes are available: 3 pod has unbound immediate PersistentVolumeClaims.\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:40:11Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Scheduled\\\",\\\"Message\\\":\\\"Successfully assigned azureml-mlrgeast/aks-service-12-696bc45d4c-gvcwn to aks-agentpool-38843976-vmss000002\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:40:22Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Container image \\\"mcr.microsoft.com/azureml/dependency-unpacker:20210714\\\" already present on machine\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:40:23Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Created\\\",\\\"Message\\\":\\\"Created container amlappinit\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:40:23Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Started\\\",\\\"Message\\\":\\\"Started container amlappinit\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:40:23Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Pulled\\\",\\\"Message\\\":\\\"Container image \\\"mlcontainerregi222.azurecr.io/azureml/azureml_dded69baa6f866c564c25bc60667a4a7\\\" already present on machine\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:40:59Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Created\\\",\\\"Message\\\":\\\"Created container aks-service-12\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:41:00Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Normal\\\",\\\"Reason\\\":\\\"Started\\\",\\\"Message\\\":\\\"Started container aks-service-12\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:41:00Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Warning\\\",\\\"Reason\\\":\\\"Unhealthy\\\",\\\"Message\\\":\\\"Readiness probe failed: HTTP probe failed with statuscode: 502\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:41:32Z\\\"}\\n{\\\"InvolvedObject\\\":\\\"aks-service-12-696bc45d4c-gvcwn\\\",\\\"InvolvedKind\\\":\\\"Pod\\\",\\\"Type\\\":\\\"Warning\\\",\\\"Reason\\\":\\\"BackOff\\\",\\\"Message\\\":\\\"Back-off restarting failed container\\\",\\\"LastTimestamp\\\":\\\"2021-10-30T08:41:38Z\\\"}\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 36,
      "metadata": {
        "tags": [
          "sample-deploy-to-aks"
        ]
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(aks_service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/bin/bash: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n/bin/bash: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so.5: no version information available (required by /bin/bash)\nbash: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so.5: no version information available (required by bash)\n2021-10-30T08:36:32,458745741+00:00 - gunicorn/run \n2021-10-30T08:36:32,456910632+00:00 - rsyslog/run \nDynamic Python package installation is disabled.\nStarting HTTP server\n2021-10-30T08:36:32,467969489+00:00 - iot-server/run \n2021-10-30T08:36:32,481813860+00:00 - nginx/run \nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n/bin/bash: /azureml-envs/azureml_a8a0845f249cc373e9e7168f4f641be5/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n2021-10-30T08:36:32,562861476+00:00 - iot-server/finish 1 0\n2021-10-30T08:36:32,563992182+00:00 - Exit code 1 is normal. Not restarting iot-server.\nStarting gunicorn 20.1.0\nListening at: http://127.0.0.1:31311 (13)\nUsing worker: sync\nworker timeout is set to 300\nBooting worker with pid: 36\nSPARK_HOME not set. Skipping PySpark Initialization.\nInitializing logger\n2021-10-30 08:36:34,581 | root | INFO | Starting up app insights client\nlogging socket was found. logging is available.\nlogging socket was found. logging is available.\n2021-10-30 08:36:34,582 | root | INFO | Starting up request id generator\n2021-10-30 08:36:34,582 | root | INFO | Starting up app insight hooks\n2021-10-30 08:36:34,582 | root | INFO | Invoking user's init function\n2021-10-30 08:36:34,582 | root | ERROR | User's init function failed\n2021-10-30 08:36:34,582 | root | ERROR | Encountered Exception Traceback (most recent call last):\n  File \"/var/azureml-server/aml_blueprint.py\", line 191, in register\n    main.init()\n  File \"/var/azureml-app/main.py\", line 35, in init\n    driver_module.init()\n  File \"/structure/azureml-app/score.py\", line 13, in init\n    model.fit(x_train, y_train, epochs=eph_size, batch_size=4,validation_data=(x_val,y_val))\nAttributeError: 'NoneType' object has no attribute 'fit'\n\n2021-10-30 08:36:34,582 | root | INFO | Waiting for logs to be sent to Application Insights before exit.\n2021-10-30 08:36:34,582 | root | INFO | Waiting 30 seconds for upload.\n\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635582999332
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the web service using run method\n",
        "We test the web sevice by passing data.\n",
        "Run() method retrieves API keys behind the scenes to make sure that call is authenticated."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import json\n",
        "\n",
        "test_sample = json.dumps({'data': [\n",
        "    [20.5, 18.1, 23.1, 2.3, 93.3, 82.0], \n",
        "    [23.7, 21.9, 26.3, 1.6, 82.6, 79.3]\n",
        "]})\n",
        "test_sample = bytes(test_sample,encoding = 'utf8')\n",
        "\n",
        "prediction = aks_service.run(input_data = test_sample)\n",
        "print(prediction)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "'NoneType' object has no attribute 'predict'\nCPU times: user 12.7 ms, sys: 8 s, total: 12.7 ms\nWall time: 233 ms\n"
        }
      ],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "token, refresh_by = aks_service.get_token()\r\n",
        "print(token)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "eyJhbGciOiJSUzI1NiIsImtpZCI6IkE3MDRDNkIzMTRDOTI3RkM2MTlGNTE2OTFCODBEQkQ2NzU2QUEyODciLCJ0eXAiOiJKV1QifQ.eyJjYW5SZWZyZXNoIjoiRmFsc2UiLCJ3b3Jrc3BhY2VJZCI6ImIyOTlkZDFhLTcyMGUtNGYzNC05NjRjLTcxODhmMmY5NDM1ZSIsInRpZCI6IjE5NDExYjNhLWI3Y2EtNDhkOS1hMWUyLTMxNjk0ZDBjY2I2NSIsIm9pZCI6IjA2OGJiZjA0LTAzZjctNGQ3OS1hZDgwLTY3NzYwN2JjNmNiNyIsImFjdGlvbnMiOiJbXCJNaWNyb3NvZnQuTWFjaGluZUxlYXJuaW5nU2VydmljZXMvd29ya3NwYWNlcy9yZWFkXCIsXCJNaWNyb3NvZnQuTWFjaGluZUxlYXJuaW5nU2VydmljZXMvd29ya3NwYWNlcy9zZXJ2aWNlcy9ha3Mvc2NvcmUvYWN0aW9uXCIsXCJNaWNyb3NvZnQuTWFjaGluZUxlYXJuaW5nU2VydmljZXMvd29ya3NwYWNlcy9vbmxpbmVFbmRwb2ludHMvc2NvcmUvYWN0aW9uXCJdIiwic2VydmljZUlkIjoiYWtzLXNlcnZpY2UtOCIsImV4cCI6MTYzNTY2NTY0MSwiaXNzIjoiYXp1cmVtbCIsImF1ZCI6ImF6dXJlbWwifQ.fWe4XN6IHQKclLPOr4AW1CKtwZ6MOVLzGTWKFPA86SVgOwJ5dIFfLh_iAzlM1jy5WlYWxtcJQiFnv688T11VqH8ULXuRx8ry-6ByclpA5L7nRuBnGDFHfC04vwR12uQNi1oR2fcKGnIE31TNavusrzkSB-XFrcPNCEDolRI0eAjXJhJonXA1aqI7-1y59aRrnfFP4kNN-ZMxT26ZFAP1AzQrHkcpL7eEJ51nHyebu_SCel1scYUTSOzNAb64aFxynq1mLIK-n7fTS4redyKzbE8fKwRcWnMmGYle9D4kf0CsB7rGv12l5zDz2zvFgdaOzkVLlGWjZ1uTcb-e7ZO9qg\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635579243457
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "primary, secondary = aks_service.get_keys()\r\n",
        "print(primary)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "ERROR:azureml.core.webservice.webservice:Received bad response from Model Management Service:\nResponse Code: 400\nHeaders: {'Date': 'Sat, 30 Oct 2021 07:34:22 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'x-ms-client-request-id': '051421d8-7be7-4c25-9824-2682a16b5214', 'x-ms-client-session-id': '93693392-1c7f-413c-919d-247528741d1d', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '0.073'}\nContent: b'{\"code\":\"BadRequest\",\"statusCode\":400,\"message\":\"The request is invalid.\",\"details\":[{\"code\":\"AuthDisabled\",\"message\":\"Authentication is disabled (authEnabled set to false). Enable service authentication to list/regenerate keys. Subscription: 932c3e14-d0cf-4e41-9998-bdebb9bfa1cf, ResourceGroup: mlrg, Workspace: mlrgeast, ACR: /subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourcegroups/mlrg/providers/microsoft.containerregistry/registries/mlcontainerregi222\"}],\"correlation\":{\"RequestId\":\"051421d8-7be7-4c25-9824-2682a16b5214\"}}'\n\n"
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Received bad response from Model Management Service:\nResponse Code: 400\nHeaders: {'Date': 'Sat, 30 Oct 2021 07:34:22 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'x-ms-client-request-id': '051421d8-7be7-4c25-9824-2682a16b5214', 'x-ms-client-session-id': '93693392-1c7f-413c-919d-247528741d1d', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '0.073'}\nContent: b'{\"code\":\"BadRequest\",\"statusCode\":400,\"message\":\"The request is invalid.\",\"details\":[{\"code\":\"AuthDisabled\",\"message\":\"Authentication is disabled (authEnabled set to false). Enable service authentication to list/regenerate keys. Subscription: 932c3e14-d0cf-4e41-9998-bdebb9bfa1cf, ResourceGroup: mlrg, Workspace: mlrgeast, ACR: /subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourcegroups/mlrg/providers/microsoft.containerregistry/registries/mlcontainerregi222\"}],\"correlation\":{\"RequestId\":\"051421d8-7be7-4c25-9824-2682a16b5214\"}}'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 400\\nHeaders: {'Date': 'Sat, 30 Oct 2021 07:34:22 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'x-ms-client-request-id': '051421d8-7be7-4c25-9824-2682a16b5214', 'x-ms-client-session-id': '93693392-1c7f-413c-919d-247528741d1d', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '0.073'}\\nContent: b'{\\\"code\\\":\\\"BadRequest\\\",\\\"statusCode\\\":400,\\\"message\\\":\\\"The request is invalid.\\\",\\\"details\\\":[{\\\"code\\\":\\\"AuthDisabled\\\",\\\"message\\\":\\\"Authentication is disabled (authEnabled set to false). Enable service authentication to list/regenerate keys. Subscription: 932c3e14-d0cf-4e41-9998-bdebb9bfa1cf, ResourceGroup: mlrg, Workspace: mlrgeast, ACR: /subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourcegroups/mlrg/providers/microsoft.containerregistry/registries/mlcontainerregi222\\\"}],\\\"correlation\\\":{\\\"RequestId\\\":\\\"051421d8-7be7-4c25-9824-2682a16b5214\\\"}}'\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mget_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClientBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_requests_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_keys_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://eastus.modelmanagement.azureml.net/modelmanagement/v1.0/subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourceGroups/mlrg/providers/Microsoft.MachineLearningServices/workspaces/mlrgeast/services/aks-service-8/listkeys",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-48362be174f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprimary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maks_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mget_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1288\u001b[0m                                       \u001b[0;34m'Headers: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m                                       \u001b[0;34m'Content: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m                                       logger=module_logger)\n\u001b[0m\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Received bad response from Model Management Service:\nResponse Code: 400\nHeaders: {'Date': 'Sat, 30 Oct 2021 07:34:22 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'x-ms-client-request-id': '051421d8-7be7-4c25-9824-2682a16b5214', 'x-ms-client-session-id': '93693392-1c7f-413c-919d-247528741d1d', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '0.073'}\nContent: b'{\"code\":\"BadRequest\",\"statusCode\":400,\"message\":\"The request is invalid.\",\"details\":[{\"code\":\"AuthDisabled\",\"message\":\"Authentication is disabled (authEnabled set to false). Enable service authentication to list/regenerate keys. Subscription: 932c3e14-d0cf-4e41-9998-bdebb9bfa1cf, ResourceGroup: mlrg, Workspace: mlrgeast, ACR: /subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourcegroups/mlrg/providers/microsoft.containerregistry/registries/mlcontainerregi222\"}],\"correlation\":{\"RequestId\":\"051421d8-7be7-4c25-9824-2682a16b5214\"}}'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from Model Management Service:\\nResponse Code: 400\\nHeaders: {'Date': 'Sat, 30 Oct 2021 07:34:22 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'x-ms-client-request-id': '051421d8-7be7-4c25-9824-2682a16b5214', 'x-ms-client-session-id': '93693392-1c7f-413c-919d-247528741d1d', 'api-supported-versions': '1.0, 2018-03-01-preview, 2018-11-19', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload', 'X-Content-Type-Options': 'nosniff', 'x-request-time': '0.073'}\\nContent: b'{\\\"code\\\":\\\"BadRequest\\\",\\\"statusCode\\\":400,\\\"message\\\":\\\"The request is invalid.\\\",\\\"details\\\":[{\\\"code\\\":\\\"AuthDisabled\\\",\\\"message\\\":\\\"Authentication is disabled (authEnabled set to false). Enable service authentication to list/regenerate keys. Subscription: 932c3e14-d0cf-4e41-9998-bdebb9bfa1cf, ResourceGroup: mlrg, Workspace: mlrgeast, ACR: /subscriptions/932c3e14-d0cf-4e41-9998-bdebb9bfa1cf/resourcegroups/mlrg/providers/microsoft.containerregistry/registries/mlcontainerregi222\\\"}],\\\"correlation\\\":{\\\"RequestId\\\":\\\"051421d8-7be7-4c25-9824-2682a16b5214\\\"}}'\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1635425334221
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the web service using raw HTTP request (optional)\n",
        "Alternatively you can construct a raw HTTP request and send it to the service. In this case you need to explicitly pass the HTTP header. This process is shown in the next 2 cells."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # if (key) auth is enabled, retrieve the API keys. AML generates two keys.\n",
        "#key1, Key2 = aks_service.get_keys()\n",
        "#print(key1)\n",
        "\n",
        "# # if token auth is enabled, retrieve the token.\n",
        "access_token, refresh_after = aks_service.get_token()"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1635579277682
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct raw HTTP request and send to the service\n",
        "#%%time\n",
        "\n",
        "import requests\n",
        "\n",
        "import json\n",
        "\n",
        "test_sample = json.dumps({'data': [\n",
        "     [20.5, 18.1, 23.1, 2.3, 93.3, 82.0], \n",
        "    [23.7, 21.9, 26.3, 1.6, 82.6, 79.3]\n",
        "]})\n",
        "test_sample = bytes(test_sample,encoding = 'utf8')\n",
        "\n",
        "# # If (key) auth is enabled, don't forget to add key to the HTTP header.\n",
        "# headers = {'Content-Type':'application/json', 'Authorization': 'Bearer ' + key1}\n",
        "\n",
        "# # If token auth is enabled, don't forget to add token to the HTTP header.\n",
        "headers = {'Content-Type':'application/json', 'Authorization': 'Bearer ' + access_token}\n",
        "\n",
        "resp = requests.post(aks_service.scoring_uri, test_sample, headers=headers)\n",
        "\n",
        "\n",
        "print(\"prediction:\", resp.text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "prediction: \"'NoneType' object has no attribute 'predict'\"\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1635579279312
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean up\n",
        "Delete the service, image and model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "aks_service.delete()\n",
        "model.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "vaidyas"
      }
    ],
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "categories": [
      "how-to-use-azureml",
      "deployment",
      "production-deploy-to-aks"
    ],
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}